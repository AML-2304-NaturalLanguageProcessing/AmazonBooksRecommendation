{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>categories</th>\n",
       "      <th>User_id</th>\n",
       "      <th>review_helpfulness</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_text</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1882931173</td>\n",
       "      <td>['Comics &amp; Graphic Novels']</td>\n",
       "      <td>AVCGYZL8FQQTD</td>\n",
       "      <td>7/7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>This is only for Julie Strain fans. It's a col...</td>\n",
       "      <td>this is only for julie strain fans its a colle...</td>\n",
       "      <td>['julie', 'strain', 'fan', 'collection', 'phot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0826414346</td>\n",
       "      <td>['Biography &amp; Autobiography']</td>\n",
       "      <td>A30TK6U7DNS82R</td>\n",
       "      <td>10/10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I don't care much for Dr. Seuss but after read...</td>\n",
       "      <td>i dont care much for dr seuss but after readin...</td>\n",
       "      <td>['dont', 'care', 'much', 'dr', 'seuss', 'readi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0826414346</td>\n",
       "      <td>['Biography &amp; Autobiography']</td>\n",
       "      <td>A3UH4UZ4RSVO82</td>\n",
       "      <td>10/11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>If people become the books they read and if \"t...</td>\n",
       "      <td>if people become the books they read and if th...</td>\n",
       "      <td>['people', 'become', 'book', 'read', 'child', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0826414346</td>\n",
       "      <td>['Biography &amp; Autobiography']</td>\n",
       "      <td>A2MVUWT453QH61</td>\n",
       "      <td>7/7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Theodore Seuss Geisel (1904-1991), aka &amp;quot;D...</td>\n",
       "      <td>theodore seuss geisel  aka quotdr seussquot wa...</td>\n",
       "      <td>['theodore', 'seuss', 'geisel', 'aka', 'quotdr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0826414346</td>\n",
       "      <td>['Biography &amp; Autobiography']</td>\n",
       "      <td>A22X4XUPKF66MR</td>\n",
       "      <td>3/3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Philip Nel - Dr. Seuss: American IconThis is b...</td>\n",
       "      <td>philip nel  dr seuss american iconthis is basi...</td>\n",
       "      <td>['philip', 'nel', 'dr', 'seuss', 'american', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          Id                     categories         User_id  \\\n",
       "0           0  1882931173    ['Comics & Graphic Novels']   AVCGYZL8FQQTD   \n",
       "1           1  0826414346  ['Biography & Autobiography']  A30TK6U7DNS82R   \n",
       "2           2  0826414346  ['Biography & Autobiography']  A3UH4UZ4RSVO82   \n",
       "3           3  0826414346  ['Biography & Autobiography']  A2MVUWT453QH61   \n",
       "4           4  0826414346  ['Biography & Autobiography']  A22X4XUPKF66MR   \n",
       "\n",
       "  review_helpfulness  review_score  \\\n",
       "0                7/7           4.0   \n",
       "1              10/10           5.0   \n",
       "2              10/11           5.0   \n",
       "3                7/7           4.0   \n",
       "4                3/3           4.0   \n",
       "\n",
       "                                         review_text  \\\n",
       "0  This is only for Julie Strain fans. It's a col...   \n",
       "1  I don't care much for Dr. Seuss but after read...   \n",
       "2  If people become the books they read and if \"t...   \n",
       "3  Theodore Seuss Geisel (1904-1991), aka &quot;D...   \n",
       "4  Philip Nel - Dr. Seuss: American IconThis is b...   \n",
       "\n",
       "                                      processed_text  \\\n",
       "0  this is only for julie strain fans its a colle...   \n",
       "1  i dont care much for dr seuss but after readin...   \n",
       "2  if people become the books they read and if th...   \n",
       "3  theodore seuss geisel  aka quotdr seussquot wa...   \n",
       "4  philip nel  dr seuss american iconthis is basi...   \n",
       "\n",
       "                                              tokens  \n",
       "0  ['julie', 'strain', 'fan', 'collection', 'phot...  \n",
       "1  ['dont', 'care', 'much', 'dr', 'seuss', 'readi...  \n",
       "2  ['people', 'become', 'book', 'read', 'child', ...  \n",
       "3  ['theodore', 'seuss', 'geisel', 'aka', 'quotdr...  \n",
       "4  ['philip', 'nel', 'dr', 'seuss', 'american', '...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/data_cleaned.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83620ff5cb974bba8c9873dde1dbf930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/285 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\annma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\annma\\.cache\\huggingface\\hub\\models--bhadresh-savani--bert-base-uncased-emotion. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1785b86f9a264091a5fc38930f8cbea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8252474ac2943e892098dfa2bd486a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b7882c335d4d0bba8f356ab7cd2e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\annma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "938eeac409914275b7d8b5eca194055d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/935 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129ccbb0941f4722bfde59ad8a742c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "model_name = \"bhadresh-savani/bert-base-uncased-emotion\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "def get_emotion_bert(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        # Get the logits from the model\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        # Get the predicted emotion\n",
    "        emotion = torch.argmax(logits, dim=1).item()\n",
    "    return emotion\n",
    "\n",
    "df['review_tokens'] = df['tokens'].apply(lambda tokens: \" \".join(tokens))\n",
    "df['emotions'] = df['review_tokens'].apply(get_emotion_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pickle\n",
    "\n",
    "# Encode emotion feature using One-Hot Encoding\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "emotion_encoded = encoder.fit_transform(df[['emotions']])\n",
    "print(\"One-Hot Encoded emotions:\\n\", emotion_encoded)\n",
    "emotion_feature_names = [f\"emotion_{i}\" for i in range(emotion_encoded.shape[1])]\n",
    "\n",
    "# Add one-hot encoded emotion features to the reviews dataframe\n",
    "emotion_df = pd.DataFrame(emotion_encoded, columns=emotion_feature_names)\n",
    "reviews_df = pd.concat([df, emotion_df], axis=1)\n",
    "# Save encoder to a pkl file\n",
    "with open(\"../model/emotion_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(encoder, f)\n",
    "\n",
    "print(\"Encoder saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
