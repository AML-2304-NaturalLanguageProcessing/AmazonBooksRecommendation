{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9083525,"sourceType":"datasetVersion","datasetId":5480558},{"sourceId":9083967,"sourceType":"datasetVersion","datasetId":5480872},{"sourceId":86942,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":73022,"modelId":97902}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nprint(f\"CUDA version: {torch.version.cuda}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-11T16:26:20.071919Z","iopub.execute_input":"2024-08-11T16:26:20.073424Z","iopub.status.idle":"2024-08-11T16:26:20.087507Z","shell.execute_reply.started":"2024-08-11T16:26:20.073314Z","shell.execute_reply":"2024-08-11T16:26:20.085972Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"PyTorch version: 2.1.2+cpu\nCUDA available: False\nCUDA version: None\n","output_type":"stream"}]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-11T16:26:20.113315Z","iopub.execute_input":"2024-08-11T16:26:20.113732Z","iopub.status.idle":"2024-08-11T16:26:20.134892Z","shell.execute_reply.started":"2024-08-11T16:26:20.113702Z","shell.execute_reply":"2024-08-11T16:26:20.133554Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"/kaggle/input/cdae/pytorch/default/1/cdae.py\n/kaggle/input/cdae-model/user_book_matrix.npz\n/kaggle/input/cdae-model/avg_embeddings_matrix.npz\n/kaggle/input/cdae-model/emotion_matrix.npz\n/kaggle/input/models/cdae.py\n","output_type":"stream"}]},{"cell_type":"code","source":"#loading libraries\nimport torch\nimport numpy as np\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom scipy.sparse import load_npz","metadata":{"execution":{"iopub.status.busy":"2024-08-11T16:26:20.137398Z","iopub.execute_input":"2024-08-11T16:26:20.137794Z","iopub.status.idle":"2024-08-11T16:26:20.145780Z","shell.execute_reply.started":"2024-08-11T16:26:20.137763Z","shell.execute_reply":"2024-08-11T16:26:20.144461Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def load_data():\n    user_book_matrix = load_npz('/kaggle/input/cdae-model/user_book_matrix.npz')\n    emotion_matrix = load_npz('/kaggle/input/cdae-model/emotion_matrix.npz')\n    book_embeddings = load_npz('/kaggle/input/cdae-model/avg_embeddings_matrix.npz')\n\n    return user_book_matrix, emotion_matrix, book_embeddings","metadata":{"execution":{"iopub.status.busy":"2024-08-11T16:26:20.147293Z","iopub.execute_input":"2024-08-11T16:26:20.147721Z","iopub.status.idle":"2024-08-11T16:26:20.157002Z","shell.execute_reply.started":"2024-08-11T16:26:20.147689Z","shell.execute_reply":"2024-08-11T16:26:20.155823Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nimport numpy as np\n\nclass CDAEDataset(Dataset):\n    def __init__(self, interactions, emotions, review_embeddings, noise_factor=0.2):\n        self.users, self.items = interactions.nonzero()\n        self.interactions = interactions.toarray()\n        self.emotions = emotions.toarray()\n        self.review_embeddings = review_embeddings.toarray()\n        self.noise_factor = noise_factor\n\n    def __len__(self):\n        return len(self.users)\n    \n    def __getitem__(self, idx):\n        user, item = self.users[idx], self.items[idx]\n        user_vector = self.interactions[user].flatten()\n        noisy_user_vector = self.add_noise(user_vector)\n        emotion_vector = torch.tensor(self.emotions[item], dtype=torch.long)\n        review_embedding = torch.tensor(self.review_embeddings[item], dtype=torch.float32)\n        \n        return (torch.FloatTensor(noisy_user_vector), \n                torch.FloatTensor(user_vector),\n                emotion_vector, \n                review_embedding,\n                torch.LongTensor([user]),\n               torch.LongTensor([item]))\n\n    def add_noise(self, vector):\n        noise = np.random.normal(loc=0, scale=self.noise_factor, size=vector.shape)\n        noisy_vector = vector + noise\n        return np.clip(noisy_vector, 0, 1)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-11T16:26:20.158790Z","iopub.execute_input":"2024-08-11T16:26:20.159184Z","iopub.status.idle":"2024-08-11T16:26:20.175502Z","shell.execute_reply.started":"2024-08-11T16:26:20.159121Z","shell.execute_reply":"2024-08-11T16:26:20.173821Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"class CDAE(nn.Module):\n    def __init__(self, num_users, num_items, num_emotions, review_embedding_dim, \n                 embedding_dim=64, hidden_dims=[256, 128, 64], dropout=0.2):\n        super(CDAE, self).__init__()\n        \n        # Embedding layers\n        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n        self.emotion_embedding = nn.Embedding(num_emotions, embedding_dim)\n        \n        # Encoder layers\n        self.encoder = nn.ModuleList()\n        input_dim = num_items + embedding_dim * 3 + review_embedding_dim  # input + user + item + emotion + review\n        encoder_dims = [input_dim] + hidden_dims\n        for i in range(len(encoder_dims) - 1):\n            self.encoder.append(nn.Linear(encoder_dims[i], encoder_dims[i+1]))\n            self.encoder.append(nn.ReLU())\n            self.encoder.append(nn.BatchNorm1d(encoder_dims[i+1]))\n            self.encoder.append(nn.Dropout(dropout))\n        \n        # Decoder layers\n        self.decoder = nn.ModuleList()\n        decoder_dims = hidden_dims[::-1] + [num_items]\n        for i in range(len(decoder_dims) - 1):\n            self.decoder.append(nn.Linear(decoder_dims[i], decoder_dims[i+1]))\n            if i < len(decoder_dims) - 2:  # No activation on the final layer\n                self.decoder.append(nn.ReLU())\n                self.decoder.append(nn.BatchNorm1d(decoder_dims[i+1]))\n                self.decoder.append(nn.Dropout(dropout))\n        \n        self.sigmoid = nn.Sigmoid()\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, user_vector, user_indices, item_indices, emotion_weights, review_embeddings,noise_factor=0.2):\n        # Add noise to the user vector\n        noisy_user_vector = user_vector + noise_factor * torch.randn_like(user_vector)\n        noisy_user_vector = torch.clamp(noisy_user_vector, 0.0, 1.0)\n        \n        #embedding lookups\n        user_emb = self.user_embedding(user_indices)\n        item_emb = self.item_embedding(item_indices)\n\n        # Handle emotion embeddings\n        emotion_emb = torch.matmul(emotion_weights, self.emotion_embedding.weight)\n\n        # Concatenate input\n        x = torch.cat([user_vector, user_emb, item_emb, emotion_emb, review_embeddings], dim=1)\n\n        # Apply dropout\n        x = self.dropout(x)\n\n        # Encode\n        for layer in self.encoder:\n            x = layer(x)\n        \n        encoded = x  # Save the encoded representation\n        \n        # Decode\n        for layer in self.decoder:\n            x = layer(x)\n        \n        # Apply sigmoid to get probabilities\n        reconstructed = self.sigmoid(x)\n        \n        return reconstructed, encoded\n\n    def get_recommendation(self, user_indices, item_indices, emotion_weights, review_embeddings):\n        with torch.no_grad():\n            # Use a zero vector as input (we're not denoising here, just reconstructing\n            user_vector = torch.zeros(user_indices.size(0), self.item_embedding.num_embeddings).to(user_indices.device)\n            reconstructed, _ = self.forward(user_vector, user_indices, item_indices, emotion_weights, review_embeddings)\n            return reconstructed","metadata":{"execution":{"iopub.status.busy":"2024-08-11T16:26:20.178757Z","iopub.execute_input":"2024-08-11T16:26:20.179208Z","iopub.status.idle":"2024-08-11T16:26:20.202016Z","shell.execute_reply.started":"2024-08-11T16:26:20.179174Z","shell.execute_reply":"2024-08-11T16:26:20.200803Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"def get_data_info(user_item_interactions, emotion_labels, review_embeddings):\n    print(f\"User-Item Interactions shape: {user_item_interactions.shape}\")\n    print(f\"Emotion Labels shape: {emotion_labels.shape}\")\n    print(f\"Review Embeddings shape: {review_embeddings.shape}\")\n    # Get the number of unique users and items\n    num_users = user_item_interactions.shape[0]\n    num_items = user_item_interactions.shape[1]\n    \n    # Get the number of unique emotions\n    num_emotions = emotion_labels.shape[1]\n    \n    # Get the dimension of review embeddings\n    review_embedding_dim = review_embeddings.shape[1]\n    \n    return num_users, num_items, num_emotions, review_embedding_dim\n","metadata":{"execution":{"iopub.status.busy":"2024-08-11T16:26:20.204154Z","iopub.execute_input":"2024-08-11T16:26:20.204651Z","iopub.status.idle":"2024-08-11T16:26:20.219197Z","shell.execute_reply.started":"2024-08-11T16:26:20.204609Z","shell.execute_reply":"2024-08-11T16:26:20.217860Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def custom_collate_fn(batch):\n    noisy_user_vectors, user_vectors, emotions, review_embeddings, user_indices,item_indices = zip(*batch)\n    \n    noisy_user_vectors = torch.stack(noisy_user_vectors)\n    user_vectors = torch.stack(user_vectors)\n    emotions = torch.stack(emotions)\n    review_embeddings = torch.stack(review_embeddings)\n    user_indices = torch.cat(user_indices)\n    \n    return noisy_user_vectors, user_vectors, emotions, review_embeddings, user_indices, item_indices\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-11T16:26:20.221586Z","iopub.execute_input":"2024-08-11T16:26:20.222049Z","iopub.status.idle":"2024-08-11T16:26:20.232448Z","shell.execute_reply.started":"2024-08-11T16:26:20.222002Z","shell.execute_reply":"2024-08-11T16:26:20.230371Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, random_split\nimport torch.optim as optim\n\nembedding_dim = 32\nreview_embedding_dim = 100\nlearning_rate = 0.001\nbatch_size = 32\nnum_epochs = 10\n\n# Load and preprocess data\nuser_item_interactions, emotion_labels, review_embeddings = load_data()\nnum_users, num_items, num_emotions, review_embedding_dim = get_data_info(user_item_interactions, emotion_labels, review_embeddings)\n\n# Create dataset\ndataset = CDAEDataset(user_item_interactions, emotion_labels, review_embeddings, noise_factor=0.2)\n\n# Split dataset into train and test\ntrain_size = int(0.8 * len(dataset))\ntest_size = len(dataset) - train_size\ntrain_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n\n# Create dataloaders\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=custom_collate_fn)\n\n# Initialize the model\nmodel = CDAE(num_users, num_items, num_emotions, review_embedding_dim, \n             embedding_dim=embedding_dim, hidden_dims=[256, 128, 64])\n\n# Move model to GPU if available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n\n# Define loss function and optimizer\ncriterion = nn.BCELoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\nimport os\nos.environ['CUDA_LAUNCH_BLOCKING'] = '1'","metadata":{"execution":{"iopub.status.busy":"2024-08-11T16:26:20.234510Z","iopub.execute_input":"2024-08-11T16:26:20.234987Z","iopub.status.idle":"2024-08-11T16:26:30.146428Z","shell.execute_reply.started":"2024-08-11T16:26:20.234947Z","shell.execute_reply":"2024-08-11T16:26:30.143452Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"User-Item Interactions shape: (575887, 74298)\nEmotion Labels shape: (74298, 6)\nReview Embeddings shape: (74298, 100)\n","output_type":"stream"}]},{"cell_type":"code","source":"def train(model, dataloader, criterion, optimizer):\n    model.train()\n    running_loss = 0.0\n\n    for noisy_user_vectors, user_vectors, emotion_weights, review_embeddings, user_indices, item_indices in train_loader:\n        noisy_user_vectors = noisy_user_vectors.to(device)\n        user_vectors = user_vectors.to(device)\n        emotion_weights = emotion_weights.to(device)\n        review_embeddings = review_embeddings.to(device)\n        user_indices = user_indices.to(device)\n        item_indices = item_indices.to(device)\n    \n        # Generate item indices (assuming they're the same as user indices in this case)\n        item_indices = user_indices.clone()\n\n        optimizer.zero_grad()\n        try:\n            prediction, _ = model(noisy_user_vectors, user_indices, item_indices, emotion_weights, review_embeddings)\n        except RuntimeError as e:\n            print(f\"Error: {e}\")\n            print(f\"Max user index: {user_indices.max().item()}\")\n            print(f\"Max item index: {item_indices.max().item()}\")\n            print(f\"Emotion weights shape: {emotion_weights.shape}\")\n            continue  # Skip this batch\n    \n        loss = criterion(prediction, user_vectors)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    average_loss = running_loss / len(dataloader)\n    return average_loss\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-11T16:26:30.152091Z","iopub.execute_input":"2024-08-11T16:26:30.152663Z","iopub.status.idle":"2024-08-11T16:26:30.167097Z","shell.execute_reply.started":"2024-08-11T16:26:30.152614Z","shell.execute_reply":"2024-08-11T16:26:30.164400Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"def validate(model, dataloader, criterion):\n    model.eval()\n    running_loss = 0.0\n\n    with torch.no_grad():\n        for noisy_user_vectors, user_vectors, emotions, review_embeddings, user_indices, item_indices in dataloader:\n            noisy_user_vectors = noisy_user_vectors.to(device)\n            user_vectors = user_vectors.to(device)\n            emotions = emotions.to(device)\n            review_embeddings = review_embeddings.to(device)\n            user_indices = user_indices.to(device)\n            item_indices = item_indices.to(device)\n\n            outputs, _ = model(noisy_user_vectors, user_indices, user_indices, user_indices, review_embeddings)\n            loss = criterion(outputs, user_vectors)\n            running_loss += loss.item()\n\n    average_loss = running_loss / len(dataloader)\n    return average_loss\n","metadata":{"execution":{"iopub.status.busy":"2024-08-11T16:26:30.170122Z","iopub.execute_input":"2024-08-11T16:26:30.170562Z","iopub.status.idle":"2024-08-11T16:26:30.188105Z","shell.execute_reply.started":"2024-08-11T16:26:30.170529Z","shell.execute_reply":"2024-08-11T16:26:30.186632Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"class EarlyStopping:\n    def __init__(self, patience=5, verbose=False, delta=0, path='cdae_checkpoint.pth'):\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.path = path\n\n    def __call__(self, val_loss, model):\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            if self.verbose:\n                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n    def save_checkpoint(self, val_loss, model):\n        \"\"\"Saves model when validation loss decreases.\"\"\"\n        if self.verbose:\n            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving CDAE model...')\n        torch.save({\n            'model_state_dict': model.state_dict(),\n            'val_loss': val_loss,\n        }, self.path)\n        self.val_loss_min = val_loss\n\n    def load_checkpoint(self, model):\n        \"\"\"Loads the best saved model.\"\"\"\n        checkpoint = torch.load(self.path)\n        model.load_state_dict(checkpoint['model_state_dict'])\n        return checkpoint['val_loss']\n","metadata":{"execution":{"iopub.status.busy":"2024-08-11T16:26:30.190028Z","iopub.execute_input":"2024-08-11T16:26:30.190485Z","iopub.status.idle":"2024-08-11T16:26:30.215882Z","shell.execute_reply.started":"2024-08-11T16:26:30.190429Z","shell.execute_reply":"2024-08-11T16:26:30.214735Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Initialize model\nmodel = CDAE(num_users, num_items, num_emotions, review_embedding_dim, \n             embedding_dim=32, hidden_dims=[256, 128, 64], dropout=0.2).to(device)\n\n# Define loss function and optimizer\ncriterion = nn.BCELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-11T16:26:30.218214Z","iopub.execute_input":"2024-08-11T16:26:30.219941Z","iopub.status.idle":"2024-08-11T16:26:31.092528Z","shell.execute_reply.started":"2024-08-11T16:26:30.219881Z","shell.execute_reply":"2024-08-11T16:26:31.090565Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"import torch\n\n# Initialize EarlyStopping object\nearly_stopping = EarlyStopping(patience=5, verbose=True, path='/kaggle/working/cdaemodel.pth')\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    for noisy_user_vectors, user_vectors, emotions, review_embeddings, user_indices, item_indices in train_loader:\n        noisy_user_vectors = noisy_user_vectors.to(device)\n        user_vectors = user_vectors.to(device)\n        emotions = emotions.to(device)\n        review_embeddings = review_embeddings.to(device)\n        user_indices = user_indices.to(device)\n        item_indices = item_indices.to(device)\n        optimizer.zero_grad()\n        try:\n            prediction, _ = model(noisy_user_vectors, user_indices, user_indices, emotions, review_embeddings)\n        except RuntimeError as e:\n            print(f\"Error: {e}\")\n            print(f\"User indices: {user_indices}\")\n            print(f\"Item indices: {user_indices}\")\n            print(f\"Emotion indices: {emotions}\")\n            continue  # Skip this batch\n        \n        loss = criterion(prediction, user_vectors)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n\n    # Compute average training loss\n    train_loss = running_loss / len(train_loader)\n\n    # Validation step\n    model.eval()\n    val_loss = 0.0\n    with torch.no_grad():\n        for noisy_user_vectors, user_vectors, emotions, review_embeddings, user_indices, item_indices in test_loader:\n            noisy_user_vectors = noisy_user_vectors.to(device)\n            user_vectors = user_vectors.to(device)\n            emotions = emotions.to(device)\n            review_embeddings = review_embeddings.to(device)\n            user_indices = user_indices.to(device)\n            item_indices = item_indices.to(device)\n\n            prediction, _ = model(noisy_user_vectors, user_indices, user_indices, emotions, review_embeddings)\n            loss = criterion(prediction, user_vectors)\n            val_loss += loss.item()\n\n        val_loss /= len(test_loader)\n\n    # Print training and validation loss\n    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n\n    # Update early stopping object\n    early_stopping(val_loss, model)\n\n    # Check if early stopping criterion is met\n    if early_stopping.early_stop:\n        print(\"Early stopping\")\n        break\n\n\n# Load the best model checkpoint\nmodel.load_state_dict(torch.load('/kaggle/working/cdaemodel.pth'))","metadata":{"execution":{"iopub.status.busy":"2024-08-11T16:26:31.094226Z","iopub.execute_input":"2024-08-11T16:26:31.094640Z","iopub.status.idle":"2024-08-11T16:26:31.575032Z","shell.execute_reply.started":"2024-08-11T16:26:31.094609Z","shell.execute_reply":"2024-08-11T16:26:31.573240Z"},"trusted":true},"execution_count":42,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[42], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m review_embeddings \u001b[38;5;241m=\u001b[39m review_embeddings\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m user_indices \u001b[38;5;241m=\u001b[39m user_indices\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 15\u001b[0m item_indices \u001b[38;5;241m=\u001b[39m \u001b[43mitem_indices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(device)\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n","\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'to'"],"ename":"AttributeError","evalue":"'tuple' object has no attribute 'to'","output_type":"error"}]}]}