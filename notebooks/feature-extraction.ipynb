{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **C. Feature Extraction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec is preferable when semantic relationships are crucial, especially with large datasets. This approach captures the context of words in a corpus and learns word associations, making it ideal for tasks such as natural language processing, recommendation systems, and understanding word similarities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Load DataSet here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign to new dataframe\n",
    "data_cleaned = data_abr_relevant\n",
    "\n",
    "# Train Word2Vec model\n",
    "data_cleaned['tokens'] = data_cleaned['tokens'].apply(ast.literal_eval)\n",
    "word2vec_model = Word2Vec(sentences=data_cleaned['tokens'], vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to extract embeddings for a list of tokens\n",
    "def extract_embeddings(tokens_list, model):\n",
    "    embeddings = []\n",
    "    for token in tokens_list:\n",
    "        if token in model.wv:\n",
    "            embeddings.append(model.wv[token])\n",
    "        else:\n",
    "            # Use zero vector for out-of-vocabulary tokens\n",
    "            embeddings.append(np.zeros(model.vector_size))  \n",
    "    if embeddings:\n",
    "        # Average of word embeddings\n",
    "        return np.mean(embeddings, axis=0)  \n",
    "    else:\n",
    "        # Return zero vector if no embeddings found\n",
    "        return np.zeros(model.vector_size)  \n",
    "\n",
    "# Apply the function to each row in df\n",
    "data_cleaned['embedding_word'] = data_cleaned['tokens'].apply(lambda tokens: extract_embeddings(tokens, word2vec_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing: Retrieve embeddings for specific tokens and verify\n",
    "test_tokens = ['aware']\n",
    "test_embeddings = extract_embeddings(test_tokens, word2vec_model)\n",
    "print(f\"Embeddings for tokens {test_tokens}:\")\n",
    "print(test_embeddings)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
