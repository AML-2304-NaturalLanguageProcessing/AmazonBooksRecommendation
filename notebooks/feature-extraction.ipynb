{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcb6f28a",
   "metadata": {
    "id": "fcb6f28a"
   },
   "source": [
    "## AML 2304 â€“ Natural Language Processing\n",
    "\n",
    "Instructor: Bhavik Gandhi\n",
    "\n",
    "Members:\n",
    "\n",
    "* Anmolpreet Kaur (C0895954)\n",
    "* Antonio Carlos De Mello Mendes (C0866063)\n",
    "* Ann Margaret Silva (C0903604)\n",
    "* Eduardo Jr Morales (C0900536)\n",
    "* Flora Mae Villarin (C0905584)\n",
    "* Maria Jessa Cruz (C0910329)\n",
    "* Prescila Mora (C0896891)\n",
    "\n",
    "Datasets:\n",
    "* Bakhet, M. (2022). Amazon Book Reviews. Kaggle. Retrieved from https://www.kaggle.com/datasets/mohamedbakhet/amazon-books-reviews?fbclid=IwZXh0bgNhZW0CMTAAAR1CeZc5I7CIAawbB9Bq_sephstdZ04MStFp0Nr1PT7vHtkIoy-wiZ33fcs_aem_ZmFrZWR1bW15MTZieXRlcw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b9b4a6",
   "metadata": {
    "id": "89b9b4a6"
   },
   "source": [
    "### **Amazon Book Recommendation with Emotion Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c976895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import torch\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from transformers import AutoTokenizer, DistilBertModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbe4663b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>categories</th>\n",
       "      <th>User_id</th>\n",
       "      <th>review_helpfulness</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_text</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>B000H9R1Q0</td>\n",
       "      <td>['Juvenile Fiction']</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0/0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I read this book before reading any other fant...</td>\n",
       "      <td>i read this book before reading any other fant...</td>\n",
       "      <td>['read', 'book', 'reading', 'fantasy', 'novel'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>B000JC6MMO</td>\n",
       "      <td>['Fiction']</td>\n",
       "      <td>A6PVMUJOXAWRM</td>\n",
       "      <td>0/0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I read this book not knowing a lot about Dean ...</td>\n",
       "      <td>i read this book not knowing a lot about dean ...</td>\n",
       "      <td>['read', 'book', 'knowing', 'lot', 'dean', 'ko...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1558322175</td>\n",
       "      <td>['Cooking']</td>\n",
       "      <td>A1OX82JPAQLL60</td>\n",
       "      <td>28/30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Villas is right, it is American, this casserol...</td>\n",
       "      <td>villas is right it is american this casserole ...</td>\n",
       "      <td>['villa', 'right', 'american', 'casserole', 'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0711217599</td>\n",
       "      <td>['Religion']</td>\n",
       "      <td>A2VE83MZF98ITY</td>\n",
       "      <td>31/31</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Augustine's 'Confessions' is among the most im...</td>\n",
       "      <td>augustines confessions is among the most impor...</td>\n",
       "      <td>['augustine', 'confession', 'among', 'importan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>B000OUEI1I</td>\n",
       "      <td>['Fiction']</td>\n",
       "      <td>ABBQNOK1V3521</td>\n",
       "      <td>1/1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>This wasn't the best written book I've ever re...</td>\n",
       "      <td>this wasnt the best written book ive ever read...</td>\n",
       "      <td>['wasnt', 'best', 'written', 'book', 'ive', 'e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          Id            categories         User_id  \\\n",
       "0           0  B000H9R1Q0  ['Juvenile Fiction']         Unknown   \n",
       "1           1  B000JC6MMO           ['Fiction']   A6PVMUJOXAWRM   \n",
       "2           2  1558322175           ['Cooking']  A1OX82JPAQLL60   \n",
       "3           3  0711217599          ['Religion']  A2VE83MZF98ITY   \n",
       "4           4  B000OUEI1I           ['Fiction']   ABBQNOK1V3521   \n",
       "\n",
       "  review_helpfulness  review_score  \\\n",
       "0                0/0           5.0   \n",
       "1                0/0           5.0   \n",
       "2              28/30           5.0   \n",
       "3              31/31           5.0   \n",
       "4                1/1           3.0   \n",
       "\n",
       "                                         review_text  \\\n",
       "0  I read this book before reading any other fant...   \n",
       "1  I read this book not knowing a lot about Dean ...   \n",
       "2  Villas is right, it is American, this casserol...   \n",
       "3  Augustine's 'Confessions' is among the most im...   \n",
       "4  This wasn't the best written book I've ever re...   \n",
       "\n",
       "                                      processed_text  \\\n",
       "0  i read this book before reading any other fant...   \n",
       "1  i read this book not knowing a lot about dean ...   \n",
       "2  villas is right it is american this casserole ...   \n",
       "3  augustines confessions is among the most impor...   \n",
       "4  this wasnt the best written book ive ever read...   \n",
       "\n",
       "                                              tokens  \n",
       "0  ['read', 'book', 'reading', 'fantasy', 'novel'...  \n",
       "1  ['read', 'book', 'knowing', 'lot', 'dean', 'ko...  \n",
       "2  ['villa', 'right', 'american', 'casserole', 'd...  \n",
       "3  ['augustine', 'confession', 'among', 'importan...  \n",
       "4  ['wasnt', 'best', 'written', 'book', 'ive', 'e...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir = \"../data\"\n",
    "\n",
    "# Load cleaned dataset\n",
    "data_cleaned = pd.read_csv(f\"{base_dir}/data_cleaned.csv\")\n",
    "\n",
    "# Display the first 5 entries of the DataFrame\n",
    "data_cleaned.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bb092b",
   "metadata": {},
   "source": [
    "#### **C. Feature Extraction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311c38c6",
   "metadata": {},
   "source": [
    "Word2Vec is preferable when semantic relationships are crucial, especially with large datasets. This approach captures the context of words in a corpus and learns word associations, making it ideal for tasks such as natural language processing, recommendation systems and understanding word similarities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "025f162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec model\n",
    "data_cleaned['tokens'] = data_cleaned['tokens'].apply(ast.literal_eval)\n",
    "word2vec_model = Word2Vec(sentences=data_cleaned['tokens'], vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to extract embeddings for a list of tokens\n",
    "def extract_embeddings(tokens_list, model):\n",
    "    embeddings = []\n",
    "    for token in tokens_list:\n",
    "        if token in model.wv:\n",
    "            embeddings.append(model.wv[token])\n",
    "        else:\n",
    "            # Use zero vector for out-of-vocabulary tokens\n",
    "            embeddings.append(np.zeros(model.vector_size))  \n",
    "    if embeddings:\n",
    "        # Average of word embeddings\n",
    "        return np.mean(embeddings, axis=0)  \n",
    "    else:\n",
    "        # Return zero vector if no embeddings found\n",
    "        return np.zeros(model.vector_size)  \n",
    "\n",
    "# Apply the function to each row in df\n",
    "data_cleaned['embedding_word'] = data_cleaned['tokens'].apply(lambda tokens: extract_embeddings(tokens, word2vec_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e33c9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings for tokens ['']:\n",
      "[0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Testing: Retrieve embeddings for specific tokens and verify\n",
    "test_tokens = ['']\n",
    "test_embeddings = extract_embeddings(test_tokens, word2vec_model)\n",
    "print(f\"Embeddings for tokens {test_tokens}:\")\n",
    "print(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31f6efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: Remove this code for embeddings using pretrained \"distilbert-base-uncased\" as it is consuming a lot of time.\n",
    "\n",
    "# Embedding using pretrained distilbert-base-uncased\n",
    "# Took time for large data\n",
    "\n",
    "data_embed_distilbert = data_cleaned.copy()\n",
    "\n",
    "# Extract the text data from the tokens column and join them into a single string for each review\n",
    "text_data = data_embed_distilbert['tokens'].apply(lambda tokens: ' '.join(tokens)).tolist()\n",
    "\n",
    "# Load the tokenizer and model\n",
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = DistilBertModel.from_pretrained(model_ckpt)\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Batch size for processing\n",
    "batch_size = 16\n",
    "\n",
    "# Function to get DistilBERT embeddings for a batch\n",
    "def get_distilbert_embeddings(text_batch, tokenizer, model):\n",
    "    inputs = tokenizer(text_batch, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "\n",
    "# Process data in batches\n",
    "embeddings = []\n",
    "for i in range(0, len(text_data), batch_size):\n",
    "    batch = text_data[i:i+batch_size]\n",
    "    batch_embeddings = get_distilbert_embeddings(batch, tokenizer, model)\n",
    "    embeddings.append(batch_embeddings)\n",
    "\n",
    "# Flatten the list of embeddings\n",
    "embeddings = np.vstack(embeddings)\n",
    "\n",
    "# Add embeddings to the DataFrame\n",
    "data_cleaned['embedding_word_distilbert'] = list(embeddings)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3b910ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned.rename(columns={'User_id': 'user_id'}, inplace=True)\n",
    "\n",
    "# Save file to local\n",
    "data_cleaned.to_csv(f\"{base_dir}/data_embedded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17f22e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>categories</th>\n",
       "      <th>user_id</th>\n",
       "      <th>review_helpfulness</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_text</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>embedding_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>B000H9R1Q0</td>\n",
       "      <td>['Juvenile Fiction']</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0/0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I read this book before reading any other fant...</td>\n",
       "      <td>i read this book before reading any other fant...</td>\n",
       "      <td>[read, book, reading, fantasy, novel, read, si...</td>\n",
       "      <td>[0.0033755056, 0.024587737, 0.029524483, -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>B000JC6MMO</td>\n",
       "      <td>['Fiction']</td>\n",
       "      <td>A6PVMUJOXAWRM</td>\n",
       "      <td>0/0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I read this book not knowing a lot about Dean ...</td>\n",
       "      <td>i read this book not knowing a lot about dean ...</td>\n",
       "      <td>[read, book, knowing, lot, dean, koontz, story...</td>\n",
       "      <td>[0.04009305, 0.008773962, 0.01123846, -0.01507...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1558322175</td>\n",
       "      <td>['Cooking']</td>\n",
       "      <td>A1OX82JPAQLL60</td>\n",
       "      <td>28/30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Villas is right, it is American, this casserol...</td>\n",
       "      <td>villas is right it is american this casserole ...</td>\n",
       "      <td>[villa, right, american, casserole, defines, r...</td>\n",
       "      <td>[0.017385779, 0.023026405, 0.01447912, 0.01746...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0711217599</td>\n",
       "      <td>['Religion']</td>\n",
       "      <td>A2VE83MZF98ITY</td>\n",
       "      <td>31/31</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Augustine's 'Confessions' is among the most im...</td>\n",
       "      <td>augustines confessions is among the most impor...</td>\n",
       "      <td>[augustine, confession, among, important, book...</td>\n",
       "      <td>[-0.0123476405, -0.00028553308, 0.024723677, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>B000OUEI1I</td>\n",
       "      <td>['Fiction']</td>\n",
       "      <td>ABBQNOK1V3521</td>\n",
       "      <td>1/1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>This wasn't the best written book I've ever re...</td>\n",
       "      <td>this wasnt the best written book ive ever read...</td>\n",
       "      <td>[wasnt, best, written, book, ive, ever, read, ...</td>\n",
       "      <td>[0.02614239, 0.0142108, 0.017003234, -0.038453...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>B000NWQXBA</td>\n",
       "      <td>['Juvenile Fiction']</td>\n",
       "      <td>A3IB92ACL9LLJ3</td>\n",
       "      <td>1/1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This was the sole book that got me into readin...</td>\n",
       "      <td>this was the sole book that got me into readin...</td>\n",
       "      <td>[sole, book, got, reading, book, used, really,...</td>\n",
       "      <td>[-3.464837e-05, 0.017863374, 0.028809272, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0838460151</td>\n",
       "      <td>['Reference']</td>\n",
       "      <td>AQJ53LIBRLGJY</td>\n",
       "      <td>7/7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>As a middle school teacher of both English lan...</td>\n",
       "      <td>as a middle school teacher of both english lan...</td>\n",
       "      <td>[middle, school, teacher, english, language, l...</td>\n",
       "      <td>[-0.0010210477, 0.012527325, -0.019546598, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1587248611</td>\n",
       "      <td>['Fiction']</td>\n",
       "      <td>A19NEUK1GR692L</td>\n",
       "      <td>0/1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Another chapter in the shopaholic series &amp; Bec...</td>\n",
       "      <td>another chapter in the shopaholic series  beck...</td>\n",
       "      <td>[another, chapter, shopaholic, series, becky, ...</td>\n",
       "      <td>[0.013754645, 0.0013688209, 0.0141074555, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>B000K4XV8O</td>\n",
       "      <td>['Religion']</td>\n",
       "      <td>A36BIIOWDYI4N7</td>\n",
       "      <td>41/89</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Contains substantial duplicity of standards. C...</td>\n",
       "      <td>contains substantial duplicity of standards cr...</td>\n",
       "      <td>[contains, substantial, duplicity, standard, c...</td>\n",
       "      <td>[0.001599986, 0.012784105, 0.039912686, -0.011...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>B000INZAJK</td>\n",
       "      <td>['Technology &amp; Engineering']</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0/0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>&amp;quot;Pest Control&amp;quot; was one of the best b...</td>\n",
       "      <td>quotpest controlquot was one of the best books...</td>\n",
       "      <td>[quotpest, controlquot, one, best, book, read,...</td>\n",
       "      <td>[0.014956436, -0.03519292, -0.0072899144, 0.01...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          Id                    categories         user_id  \\\n",
       "0           0  B000H9R1Q0          ['Juvenile Fiction']         Unknown   \n",
       "1           1  B000JC6MMO                   ['Fiction']   A6PVMUJOXAWRM   \n",
       "2           2  1558322175                   ['Cooking']  A1OX82JPAQLL60   \n",
       "3           3  0711217599                  ['Religion']  A2VE83MZF98ITY   \n",
       "4           4  B000OUEI1I                   ['Fiction']   ABBQNOK1V3521   \n",
       "5           5  B000NWQXBA          ['Juvenile Fiction']  A3IB92ACL9LLJ3   \n",
       "6           6  0838460151                 ['Reference']   AQJ53LIBRLGJY   \n",
       "7           7  1587248611                   ['Fiction']  A19NEUK1GR692L   \n",
       "8           8  B000K4XV8O                  ['Religion']  A36BIIOWDYI4N7   \n",
       "9           9  B000INZAJK  ['Technology & Engineering']         Unknown   \n",
       "\n",
       "  review_helpfulness  review_score  \\\n",
       "0                0/0           5.0   \n",
       "1                0/0           5.0   \n",
       "2              28/30           5.0   \n",
       "3              31/31           5.0   \n",
       "4                1/1           3.0   \n",
       "5                1/1           5.0   \n",
       "6                7/7           5.0   \n",
       "7                0/1           5.0   \n",
       "8              41/89           3.0   \n",
       "9                0/0           4.0   \n",
       "\n",
       "                                         review_text  \\\n",
       "0  I read this book before reading any other fant...   \n",
       "1  I read this book not knowing a lot about Dean ...   \n",
       "2  Villas is right, it is American, this casserol...   \n",
       "3  Augustine's 'Confessions' is among the most im...   \n",
       "4  This wasn't the best written book I've ever re...   \n",
       "5  This was the sole book that got me into readin...   \n",
       "6  As a middle school teacher of both English lan...   \n",
       "7  Another chapter in the shopaholic series & Bec...   \n",
       "8  Contains substantial duplicity of standards. C...   \n",
       "9  &quot;Pest Control&quot; was one of the best b...   \n",
       "\n",
       "                                      processed_text  \\\n",
       "0  i read this book before reading any other fant...   \n",
       "1  i read this book not knowing a lot about dean ...   \n",
       "2  villas is right it is american this casserole ...   \n",
       "3  augustines confessions is among the most impor...   \n",
       "4  this wasnt the best written book ive ever read...   \n",
       "5  this was the sole book that got me into readin...   \n",
       "6  as a middle school teacher of both english lan...   \n",
       "7  another chapter in the shopaholic series  beck...   \n",
       "8  contains substantial duplicity of standards cr...   \n",
       "9  quotpest controlquot was one of the best books...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [read, book, reading, fantasy, novel, read, si...   \n",
       "1  [read, book, knowing, lot, dean, koontz, story...   \n",
       "2  [villa, right, american, casserole, defines, r...   \n",
       "3  [augustine, confession, among, important, book...   \n",
       "4  [wasnt, best, written, book, ive, ever, read, ...   \n",
       "5  [sole, book, got, reading, book, used, really,...   \n",
       "6  [middle, school, teacher, english, language, l...   \n",
       "7  [another, chapter, shopaholic, series, becky, ...   \n",
       "8  [contains, substantial, duplicity, standard, c...   \n",
       "9  [quotpest, controlquot, one, best, book, read,...   \n",
       "\n",
       "                                      embedding_word  \n",
       "0  [0.0033755056, 0.024587737, 0.029524483, -0.00...  \n",
       "1  [0.04009305, 0.008773962, 0.01123846, -0.01507...  \n",
       "2  [0.017385779, 0.023026405, 0.01447912, 0.01746...  \n",
       "3  [-0.0123476405, -0.00028553308, 0.024723677, -...  \n",
       "4  [0.02614239, 0.0142108, 0.017003234, -0.038453...  \n",
       "5  [-3.464837e-05, 0.017863374, 0.028809272, 0.02...  \n",
       "6  [-0.0010210477, 0.012527325, -0.019546598, -0....  \n",
       "7  [0.013754645, 0.0013688209, 0.0141074555, 0.00...  \n",
       "8  [0.001599986, 0.012784105, 0.039912686, -0.011...  \n",
       "9  [0.014956436, -0.03519292, -0.0072899144, 0.01...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
