{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcb6f28a",
   "metadata": {
    "id": "fcb6f28a"
   },
   "source": [
    "## AML 2304 â€“ Natural Language Processing\n",
    "\n",
    "Instructor: Bhavik Gandhi\n",
    "\n",
    "Members:\n",
    "\n",
    "* Anmolpreet Kaur (C0895954)\n",
    "* Antonio Carlos De Mello Mendes (C0866063)\n",
    "* Ann Margaret Silva (C0903604)\n",
    "* Eduardo Jr Morales (C0900536)\n",
    "* Flora Mae Villarin (C0905584)\n",
    "* Maria Jessa Cruz (C0910329)\n",
    "* Prescila Mora (C0896891)\n",
    "\n",
    "Datasets:\n",
    "* Bakhet, M. (2022). Amazon Book Reviews. Kaggle. Retrieved from https://www.kaggle.com/datasets/mohamedbakhet/amazon-books-reviews?fbclid=IwZXh0bgNhZW0CMTAAAR1CeZc5I7CIAawbB9Bq_sephstdZ04MStFp0Nr1PT7vHtkIoy-wiZ33fcs_aem_ZmFrZWR1bW15MTZieXRlcw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b9b4a6",
   "metadata": {
    "id": "89b9b4a6"
   },
   "source": [
    "### **Amazon Book Recommendation with Emotion Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c976895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import torch\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from transformers import AutoTokenizer, DistilBertModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbe4663b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>categories</th>\n",
       "      <th>User_id</th>\n",
       "      <th>review_helpfulness</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_text</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1882931173</td>\n",
       "      <td>['Comics &amp; Graphic Novels']</td>\n",
       "      <td>AVCGYZL8FQQTD</td>\n",
       "      <td>7/7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>This is only for Julie Strain fans. It's a col...</td>\n",
       "      <td>this is only for julie strain fans its a colle...</td>\n",
       "      <td>['julie', 'strain', 'fan', 'collection', 'phot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0826414346</td>\n",
       "      <td>['Biography &amp; Autobiography']</td>\n",
       "      <td>A30TK6U7DNS82R</td>\n",
       "      <td>10/10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I don't care much for Dr. Seuss but after read...</td>\n",
       "      <td>i dont care much for dr seuss but after readin...</td>\n",
       "      <td>['dont', 'care', 'much', 'dr', 'seuss', 'readi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0826414346</td>\n",
       "      <td>['Biography &amp; Autobiography']</td>\n",
       "      <td>A3UH4UZ4RSVO82</td>\n",
       "      <td>10/11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>If people become the books they read and if \"t...</td>\n",
       "      <td>if people become the books they read and if th...</td>\n",
       "      <td>['people', 'become', 'book', 'read', 'child', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0826414346</td>\n",
       "      <td>['Biography &amp; Autobiography']</td>\n",
       "      <td>A2MVUWT453QH61</td>\n",
       "      <td>7/7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Theodore Seuss Geisel (1904-1991), aka &amp;quot;D...</td>\n",
       "      <td>theodore seuss geisel  aka quotdr seussquot wa...</td>\n",
       "      <td>['theodore', 'seuss', 'geisel', 'aka', 'quotdr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0826414346</td>\n",
       "      <td>['Biography &amp; Autobiography']</td>\n",
       "      <td>A22X4XUPKF66MR</td>\n",
       "      <td>3/3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Philip Nel - Dr. Seuss: American IconThis is b...</td>\n",
       "      <td>philip nel  dr seuss american iconthis is basi...</td>\n",
       "      <td>['philip', 'nel', 'dr', 'seuss', 'american', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          Id                     categories         User_id  \\\n",
       "0           0  1882931173    ['Comics & Graphic Novels']   AVCGYZL8FQQTD   \n",
       "1           1  0826414346  ['Biography & Autobiography']  A30TK6U7DNS82R   \n",
       "2           2  0826414346  ['Biography & Autobiography']  A3UH4UZ4RSVO82   \n",
       "3           3  0826414346  ['Biography & Autobiography']  A2MVUWT453QH61   \n",
       "4           4  0826414346  ['Biography & Autobiography']  A22X4XUPKF66MR   \n",
       "\n",
       "  review_helpfulness  review_score  \\\n",
       "0                7/7           4.0   \n",
       "1              10/10           5.0   \n",
       "2              10/11           5.0   \n",
       "3                7/7           4.0   \n",
       "4                3/3           4.0   \n",
       "\n",
       "                                         review_text  \\\n",
       "0  This is only for Julie Strain fans. It's a col...   \n",
       "1  I don't care much for Dr. Seuss but after read...   \n",
       "2  If people become the books they read and if \"t...   \n",
       "3  Theodore Seuss Geisel (1904-1991), aka &quot;D...   \n",
       "4  Philip Nel - Dr. Seuss: American IconThis is b...   \n",
       "\n",
       "                                      processed_text  \\\n",
       "0  this is only for julie strain fans its a colle...   \n",
       "1  i dont care much for dr seuss but after readin...   \n",
       "2  if people become the books they read and if th...   \n",
       "3  theodore seuss geisel  aka quotdr seussquot wa...   \n",
       "4  philip nel  dr seuss american iconthis is basi...   \n",
       "\n",
       "                                              tokens  \n",
       "0  ['julie', 'strain', 'fan', 'collection', 'phot...  \n",
       "1  ['dont', 'care', 'much', 'dr', 'seuss', 'readi...  \n",
       "2  ['people', 'become', 'book', 'read', 'child', ...  \n",
       "3  ['theodore', 'seuss', 'geisel', 'aka', 'quotdr...  \n",
       "4  ['philip', 'nel', 'dr', 'seuss', 'american', '...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load cleaned dataset\n",
    "data_cleaned = pd.read_csv('/kaggle/input/amazon/data_cleaned.csv')\n",
    "\n",
    "# Display the first 5 entries of the DataFrame\n",
    "data_cleaned.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bb092b",
   "metadata": {},
   "source": [
    "#### **C. Feature Extraction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311c38c6",
   "metadata": {},
   "source": [
    "Word2Vec is preferable when semantic relationships are crucial, especially with large datasets. This approach captures the context of words in a corpus and learns word associations, making it ideal for tasks such as natural language processing, recommendation systems and understanding word similarities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "025f162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec model\n",
    "data_cleaned['tokens'] = data_cleaned['tokens'].apply(ast.literal_eval)\n",
    "word2vec_model = Word2Vec(sentences=data_cleaned['tokens'], vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to extract embeddings for a list of tokens\n",
    "def extract_embeddings(tokens_list, model):\n",
    "    embeddings = []\n",
    "    for token in tokens_list:\n",
    "        if token in model.wv:\n",
    "            embeddings.append(model.wv[token])\n",
    "        else:\n",
    "            # Use zero vector for out-of-vocabulary tokens\n",
    "            embeddings.append(np.zeros(model.vector_size))  \n",
    "    if embeddings:\n",
    "        # Average of word embeddings\n",
    "        return np.mean(embeddings, axis=0)  \n",
    "    else:\n",
    "        # Return zero vector if no embeddings found\n",
    "        return np.zeros(model.vector_size)  \n",
    "\n",
    "# Apply the function to each row in df\n",
    "data_cleaned['embedding_word'] = data_cleaned['tokens'].apply(lambda tokens: extract_embeddings(tokens, word2vec_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e33c9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings for tokens ['']:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Testing: Retrieve embeddings for specific tokens and verify\n",
    "test_tokens = ['']\n",
    "test_embeddings = extract_embeddings(test_tokens, word2vec_model)\n",
    "print(f\"Embeddings for tokens {test_tokens}:\")\n",
    "print(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31f6efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding using pretrained distilbert-base-uncased\n",
    "# Took time for large data\n",
    "\n",
    "data_embed_distilbert = data_cleaned.copy()\n",
    "\n",
    "# Extract the text data from the tokens column and join them into a single string for each review\n",
    "text_data = data_embed_distilbert['tokens'].apply(lambda tokens: ' '.join(tokens)).tolist()\n",
    "\n",
    "# Load the tokenizer and model\n",
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = DistilBertModel.from_pretrained(model_ckpt)\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Batch size for processing\n",
    "batch_size = 16\n",
    "\n",
    "# Function to get DistilBERT embeddings for a batch\n",
    "def get_distilbert_embeddings(text_batch, tokenizer, model):\n",
    "    inputs = tokenizer(text_batch, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "\n",
    "# Process data in batches\n",
    "embeddings = []\n",
    "for i in range(0, len(text_data), batch_size):\n",
    "    batch = text_data[i:i+batch_size]\n",
    "    batch_embeddings = get_distilbert_embeddings(batch, tokenizer, model)\n",
    "    embeddings.append(batch_embeddings)\n",
    "\n",
    "# Flatten the list of embeddings\n",
    "embeddings = np.vstack(embeddings)\n",
    "\n",
    "# Add embeddings to the DataFrame\n",
    "data_cleaned['embedding_word_distilbert'] = list(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3b910ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save file to local\n",
    "data_cleaned.to_csv(\"data_embedded.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
