{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "class NCFDataset(Dataset):\n",
    "    def __init__(self, interactions, emotions, review_embeddings):\n",
    "        self.users, self.items = interactions.nonzero()\n",
    "        self.ratings = interactions[self.users, self.items].A1\n",
    "        self.emotions = emotions[self.items].toarray()  # Convert to dense array\n",
    "        self.review_embeddings = review_embeddings[self.items].toarray()  # Convert to dense array\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.users[idx], self.items[idx], self.emotions[idx], \n",
    "                self.review_embeddings[idx], self.ratings[idx])\n",
    "\n",
    "class NCF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, num_emotions, review_embedding_dim, \n",
    "                 embedding_dim=64, mlp_dims=[256, 128, 64], dropout=0.2):\n",
    "        super(NCF, self).__init__()\n",
    "        \n",
    "        # Embedding layers\n",
    "        self.user_embedding_mf = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding_mf = nn.Embedding(num_items, embedding_dim)\n",
    "        self.user_embedding_mlp = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding_mlp = nn.Embedding(num_items, embedding_dim)\n",
    "        self.emotion_embedding = nn.Embedding(num_emotions, embedding_dim)\n",
    "        \n",
    "        # MF layer\n",
    "        self.mf_output = embedding_dim\n",
    "        \n",
    "        # MLP layers\n",
    "        self.mlp = nn.ModuleList()\n",
    "        input_dim = embedding_dim * 3 + review_embedding_dim  # user + item + emotion + review\n",
    "        mlp_dims = [input_dim] + mlp_dims\n",
    "        for i in range(len(mlp_dims) - 1):\n",
    "            self.mlp.append(nn.Linear(mlp_dims[i], mlp_dims[i+1]))\n",
    "            self.mlp.append(nn.ReLU())\n",
    "            self.mlp.append(nn.BatchNorm1d(mlp_dims[i+1]))\n",
    "            self.mlp.append(nn.Dropout(dropout))\n",
    "        \n",
    "        # Final prediction layer\n",
    "        self.final = nn.Linear(self.mf_output + mlp_dims[-1], 1)\n",
    "        \n",
    "    def forward(self, user_indices, item_indices, emotion_indices, review_embeddings):\n",
    "        # MF component\n",
    "        user_embedding_mf = self.user_embedding_mf(user_indices)\n",
    "        item_embedding_mf = self.item_embedding_mf(item_indices)\n",
    "        mf_vector = torch.mul(user_embedding_mf, item_embedding_mf)\n",
    "        \n",
    "        # MLP component\n",
    "        user_embedding_mlp = self.user_embedding_mlp(user_indices)\n",
    "        item_embedding_mlp = self.item_embedding_mlp(item_indices)\n",
    "        emotion_embedding = self.emotion_embedding(emotion_indices)\n",
    "        emotion_embedding = self.emotion_embedding(emotion_indices).mean(dim=1)  # Adjusted for mean over emotions\n",
    "        mlp_vector = torch.cat([user_embedding_mlp, item_embedding_mlp, emotion_embedding, review_embeddings], dim=-1)\n",
    " \n",
    "        for layer in self.mlp:\n",
    "            mlp_vector = layer(mlp_vector)\n",
    "        \n",
    "        # Combine MF and MLP\n",
    "        combined = torch.cat([mf_vector, mlp_vector], dim=-1)\n",
    "        \n",
    "        # Final prediction\n",
    "        prediction = self.final(combined)\n",
    "        \n",
    "        return prediction.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data split\n",
    "test_dataset = torch.load(\"/Users/User/Downloads/test_dataset.pth/test_dataset.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model MSE: 0.02643394988215008\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Load the model state dictionaries\n",
    "state_dict1 = torch.load('/Users/User/Downloads/NCF_model.pth', map_location=torch.device('cpu'))\n",
    "state_dict2 = torch.load('/Users/User/Downloads/NCF_model.pth', map_location=torch.device('cpu'))\n",
    "\n",
    "# Recreate the model architecture\n",
    "def create_model(state_dict):\n",
    "    num_users = state_dict['user_embedding_mf.weight'].shape[0]\n",
    "    num_items = state_dict['item_embedding_mf.weight'].shape[0]\n",
    "    num_emotions = state_dict['emotion_embedding.weight'].shape[0]\n",
    "    embedding_dim = state_dict['user_embedding_mf.weight'].shape[1]  # This should be 32\n",
    "    review_embedding_dim = state_dict['mlp.0.weight'].shape[1] - 3 * embedding_dim\n",
    "\n",
    "    # Adjust the NCF class initialization to match the saved model\n",
    "    model = NCF(num_users, num_items, num_emotions, review_embedding_dim, embedding_dim=embedding_dim)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Create two model instances\n",
    "model1 = create_model(state_dict1)\n",
    "model2 = create_model(state_dict2)\n",
    "\n",
    "# Create a DataLoader for the test dataset\n",
    "batch_size = 64  # Adjust as needed\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Function to make predictions\n",
    "def make_predictions(model, loader):\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            user_indices, item_indices, emotions, review_embeddings, _ = batch\n",
    "            # Convert indices to Long (integer) type\n",
    "            user_indices = user_indices.long()\n",
    "            item_indices = item_indices.long()\n",
    "            emotions = emotions.long()\n",
    "            review_embeddings = review_embeddings.float()\n",
    "            outputs = model(user_indices, item_indices, emotions, review_embeddings)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "    return np.array(predictions)\n",
    "\n",
    "# Make predictions with both models\n",
    "predictions1 = make_predictions(model1, test_loader)\n",
    "predictions2 = make_predictions(model2, test_loader)\n",
    "\n",
    "# Ensemble the predictions\n",
    "ensemble_predictions = (predictions1 + predictions2) / 2\n",
    "\n",
    "# Get the true ratings\n",
    "true_ratings = []\n",
    "for batch in test_loader:\n",
    "    _, _, _, _, ratings = batch\n",
    "    true_ratings.extend(ratings.cpu().numpy())\n",
    "true_ratings = np.array(true_ratings)\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(true_ratings, ensemble_predictions)\n",
    "print(f\"Ensemble Model MSE: {mse}\")\n",
    "\n",
    "# Optional: Save the ensemble model\n",
    "ensemble_model = {\n",
    "    'model1': model1.state_dict(),\n",
    "    'model2': model2.state_dict(),\n",
    "    'weights': [0.5, 0.5]  # Equal weights for both models\n",
    "}\n",
    "\n",
    "torch.save(ensemble_model, 'ensemble_ncf_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
