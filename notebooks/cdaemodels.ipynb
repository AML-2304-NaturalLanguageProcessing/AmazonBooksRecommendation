{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "304180bf",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-01T17:17:58.679346Z",
     "iopub.status.busy": "2024-08-01T17:17:58.678498Z",
     "iopub.status.idle": "2024-08-01T17:17:59.465638Z",
     "shell.execute_reply": "2024-08-01T17:17:59.464761Z"
    },
    "papermill": {
     "duration": 0.79599,
     "end_time": "2024-08-01T17:17:59.468042",
     "exception": false,
     "start_time": "2024-08-01T17:17:58.672052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/cdae/pytorch/default/1/cdae.py\n",
      "/kaggle/input/models/cdae.py\n",
      "/kaggle/input/cdae-model/user_book_matrix.npz\n",
      "/kaggle/input/cdae-model/avg_embeddings_matrix.npz\n",
      "/kaggle/input/cdae-model/emotion_matrix.npz\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ad505ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-01T17:17:59.478613Z",
     "iopub.status.busy": "2024-08-01T17:17:59.477909Z",
     "iopub.status.idle": "2024-08-01T17:18:03.664724Z",
     "shell.execute_reply": "2024-08-01T17:18:03.663824Z"
    },
    "papermill": {
     "duration": 4.194588,
     "end_time": "2024-08-01T17:18:03.667129",
     "exception": false,
     "start_time": "2024-08-01T17:17:59.472541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#loading libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.sparse import load_npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb0af0fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-01T17:18:03.678399Z",
     "iopub.status.busy": "2024-08-01T17:18:03.677926Z",
     "iopub.status.idle": "2024-08-01T17:18:03.683393Z",
     "shell.execute_reply": "2024-08-01T17:18:03.682435Z"
    },
    "papermill": {
     "duration": 0.013316,
     "end_time": "2024-08-01T17:18:03.685433",
     "exception": false,
     "start_time": "2024-08-01T17:18:03.672117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    user_book_matrix = load_npz('/kaggle/input/cdae-model/user_book_matrix.npz')\n",
    "    emotion_matrix = load_npz('/kaggle/input/cdae-model/emotion_matrix.npz')\n",
    "    book_embeddings = load_npz('/kaggle/input/cdae-model/avg_embeddings_matrix.npz')\n",
    "\n",
    "    return user_book_matrix, emotion_matrix, book_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2aa1fa3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-01T17:18:03.695445Z",
     "iopub.status.busy": "2024-08-01T17:18:03.695180Z",
     "iopub.status.idle": "2024-08-01T17:18:03.705841Z",
     "shell.execute_reply": "2024-08-01T17:18:03.704964Z"
    },
    "papermill": {
     "duration": 0.018075,
     "end_time": "2024-08-01T17:18:03.707827",
     "exception": false,
     "start_time": "2024-08-01T17:18:03.689752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class CDAEDataset(Dataset):\n",
    "    def __init__(self, interactions, emotions, review_embeddings, noise_factor=0.2):\n",
    "        self.users, self.items = interactions.nonzero()\n",
    "        self.interactions = interactions.toarray()  # Convert to dense array\n",
    "        self.emotions = emotions.toarray()  # Convert to dense array\n",
    "        self.review_embeddings = review_embeddings.toarray()  # Convert to dense array\n",
    "        self.noise_factor = noise_factor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)  # Number of user-item interactions\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        user, item = self.users[idx], self.items[idx]\n",
    "        user_vector = self.interactions[user].flatten()\n",
    "        \n",
    "        # Add noise to the user vector\n",
    "        noisy_user_vector = self.add_noise(user_vector)\n",
    "        \n",
    "        # Get corresponding emotions and review embeddings for the item\n",
    "        emotion_vector = torch.tensor(self.emotions[item], dtype=torch.float32)\n",
    "        review_embedding = torch.tensor(self.review_embeddings[item], dtype=torch.float32)\n",
    "        \n",
    "        return (torch.FloatTensor(noisy_user_vector), \n",
    "                torch.FloatTensor(user_vector),\n",
    "                emotion_vector, \n",
    "                review_embedding,\n",
    "                torch.LongTensor([user]))\n",
    "\n",
    "    def add_noise(self, vector):\n",
    "        noise = np.random.normal(loc=0, scale=self.noise_factor, size=vector.shape)\n",
    "        noisy_vector = vector + noise\n",
    "        return np.clip(noisy_vector, 0, 1)  # Ensure values are between 0 and 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85d40a51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-01T17:18:03.718123Z",
     "iopub.status.busy": "2024-08-01T17:18:03.717794Z",
     "iopub.status.idle": "2024-08-01T17:18:03.733517Z",
     "shell.execute_reply": "2024-08-01T17:18:03.732565Z"
    },
    "papermill": {
     "duration": 0.023157,
     "end_time": "2024-08-01T17:18:03.735426",
     "exception": false,
     "start_time": "2024-08-01T17:18:03.712269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CDAE(nn.Module):\n",
    "    def __init__(self, num_users, num_items, num_emotions, review_embedding_dim, \n",
    "                 embedding_dim=64, hidden_dims=[256, 128, 64], dropout=0.2):\n",
    "        super(CDAE, self).__init__()\n",
    "        \n",
    "        # Embedding layers\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        self.emotion_embedding = nn.Embedding(num_emotions, embedding_dim)\n",
    "        \n",
    "        # Encoder layers\n",
    "        self.encoder = nn.ModuleList()\n",
    "        input_dim = num_items + embedding_dim * 3 + review_embedding_dim  # input + user + item + emotion + review\n",
    "        encoder_dims = [input_dim] + hidden_dims\n",
    "        for i in range(len(encoder_dims) - 1):\n",
    "            self.encoder.append(nn.Linear(encoder_dims[i], encoder_dims[i+1]))\n",
    "            self.encoder.append(nn.ReLU())\n",
    "            self.encoder.append(nn.BatchNorm1d(encoder_dims[i+1]))\n",
    "            self.encoder.append(nn.Dropout(dropout))\n",
    "        \n",
    "        # Decoder layers\n",
    "        self.decoder = nn.ModuleList()\n",
    "        decoder_dims = hidden_dims[::-1] + [num_items]\n",
    "        for i in range(len(decoder_dims) - 1):\n",
    "            self.decoder.append(nn.Linear(decoder_dims[i], decoder_dims[i+1]))\n",
    "            if i < len(decoder_dims) - 2:  # No activation on the final layer\n",
    "                self.decoder.append(nn.ReLU())\n",
    "                self.decoder.append(nn.BatchNorm1d(decoder_dims[i+1]))\n",
    "                self.decoder.append(nn.Dropout(dropout))\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, user_vector, user_indices, item_indices, emotion_indices, review_embeddings):\n",
    "        # Get embeddings\n",
    "        user_emb = self.user_embedding(user_indices)\n",
    "        item_emb = self.item_embedding(item_indices)\n",
    "        emotion_emb = self.emotion_embedding(emotion_indices).mean(dim=1)  # Mean over emotions\n",
    "        \n",
    "        # Concatenate input\n",
    "        x = torch.cat([user_vector, user_emb, item_emb, emotion_emb, review_embeddings], dim=1)\n",
    "        \n",
    "        # Encode\n",
    "        for layer in self.encoder:\n",
    "            x = layer(x)\n",
    "        \n",
    "        encoded = x  # Save the encoded representation\n",
    "        \n",
    "        # Decode\n",
    "        for layer in self.decoder:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # Apply sigmoid to get probabilities\n",
    "        reconstructed = self.sigmoid(x)\n",
    "        \n",
    "        return reconstructed, encoded\n",
    "\n",
    "    def get_recommendation(self, user_indices, item_indices, emotion_indices, review_embeddings):\n",
    "        with torch.no_grad():\n",
    "            # Use a zero vector as input (we're not denoising here, just reconstructing)\n",
    "            user_vector = torch.zeros(user_indices.size(0), self.item_embedding.num_embeddings).to(user_indices.device)\n",
    "            \n",
    "            reconstructed, _ = self.forward(user_vector, user_indices, item_indices, emotion_indices, review_embeddings)\n",
    "            \n",
    "            return reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a6b44e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-01T17:18:03.745475Z",
     "iopub.status.busy": "2024-08-01T17:18:03.745186Z",
     "iopub.status.idle": "2024-08-01T17:18:03.750818Z",
     "shell.execute_reply": "2024-08-01T17:18:03.749975Z"
    },
    "papermill": {
     "duration": 0.012932,
     "end_time": "2024-08-01T17:18:03.752722",
     "exception": false,
     "start_time": "2024-08-01T17:18:03.739790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data_info(user_item_interactions, emotion_labels, review_embeddings):\n",
    "    print(f\"User-Item Interactions shape: {user_item_interactions.shape}\")\n",
    "    print(f\"Emotion Labels shape: {emotion_labels.shape}\")\n",
    "    print(f\"Review Embeddings shape: {review_embeddings.shape}\")\n",
    "    # Get the number of unique users and items\n",
    "    num_users = user_item_interactions.shape[0]\n",
    "    num_items = user_item_interactions.shape[1]\n",
    "    \n",
    "    # Get the number of unique emotions\n",
    "    num_emotions = emotion_labels.shape[1]\n",
    "    \n",
    "    # Get the dimension of review embeddings\n",
    "    review_embedding_dim = review_embeddings.shape[1]\n",
    "    \n",
    "    return num_users, num_items, num_emotions, review_embedding_dim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98a64c5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-01T17:18:03.762627Z",
     "iopub.status.busy": "2024-08-01T17:18:03.762326Z",
     "iopub.status.idle": "2024-08-01T17:18:03.767584Z",
     "shell.execute_reply": "2024-08-01T17:18:03.766745Z"
    },
    "papermill": {
     "duration": 0.012762,
     "end_time": "2024-08-01T17:18:03.769714",
     "exception": false,
     "start_time": "2024-08-01T17:18:03.756952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    user_vectors, user_indices, emotions, review_embeddings = zip(*batch)\n",
    "    \n",
    "    user_vectors = torch.stack(user_vectors)\n",
    "    user_indices = torch.tensor(user_indices, dtype=torch.long)\n",
    "    emotions = torch.stack(emotions)\n",
    "    review_embeddings = torch.stack(review_embeddings)\n",
    "    \n",
    "    return user_vectors, user_indices, emotions, review_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "177cf81b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-01T17:18:03.780119Z",
     "iopub.status.busy": "2024-08-01T17:18:03.779595Z",
     "iopub.status.idle": "2024-08-01T17:18:12.905615Z",
     "shell.execute_reply": "2024-08-01T17:18:12.904777Z"
    },
    "papermill": {
     "duration": 9.133635,
     "end_time": "2024-08-01T17:18:12.907971",
     "exception": false,
     "start_time": "2024-08-01T17:18:03.774336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-Item Interactions shape: (575887, 74298)\n",
      "Emotion Labels shape: (74298, 6)\n",
      "Review Embeddings shape: (74298, 100)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "\n",
    "embedding_dim = 32\n",
    "review_embedding_dim = 100\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "\n",
    "# Load and preprocess data\n",
    "user_item_interactions, emotion_labels, review_embeddings = load_data()\n",
    "num_users, num_items, num_emotions, review_embedding_dim = get_data_info(user_item_interactions, emotion_labels, review_embeddings)\n",
    "\n",
    "# Create dataset\n",
    "dataset = CDAEDataset(user_item_interactions, emotion_labels, review_embeddings, noise_factor=0.2)\n",
    "\n",
    "# Split dataset into train and test\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=custom_collate_fn)\n",
    "\n",
    "# Initialize the model\n",
    "model = CDAE(num_users, num_items, num_emotions, review_embedding_dim, \n",
    "             embedding_dim=embedding_dim, hidden_dims=[256, 128, 64])\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "565045e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-01T17:18:12.918926Z",
     "iopub.status.busy": "2024-08-01T17:18:12.918431Z",
     "iopub.status.idle": "2024-08-01T17:18:12.925796Z",
     "shell.execute_reply": "2024-08-01T17:18:12.924952Z"
    },
    "papermill": {
     "duration": 0.015048,
     "end_time": "2024-08-01T17:18:12.927873",
     "exception": false,
     "start_time": "2024-08-01T17:18:12.912825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for noisy_user_vectors, user_vectors, emotions, review_embeddings, user_indices in dataloader:\n",
    "        noisy_user_vectors = noisy_user_vectors.to(device)\n",
    "        user_vectors = user_vectors.to(device)\n",
    "        emotions = emotions.to(device)\n",
    "        review_embeddings = review_embeddings.to(device)\n",
    "        user_indices = user_indices.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs, _ = model(noisy_user_vectors, user_indices, user_indices, emotions, review_embeddings)\n",
    "        loss = criterion(outputs, user_vectors)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    average_loss = running_loss / len(dataloader)\n",
    "    return average_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad8d319b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-01T17:18:12.938077Z",
     "iopub.status.busy": "2024-08-01T17:18:12.937751Z",
     "iopub.status.idle": "2024-08-01T17:18:12.944497Z",
     "shell.execute_reply": "2024-08-01T17:18:12.943652Z"
    },
    "papermill": {
     "duration": 0.014099,
     "end_time": "2024-08-01T17:18:12.946424",
     "exception": false,
     "start_time": "2024-08-01T17:18:12.932325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for noisy_user_vectors, user_vectors, emotions, review_embeddings, user_indices in dataloader:\n",
    "            noisy_user_vectors = noisy_user_vectors.to(device)\n",
    "            user_vectors = user_vectors.to(device)\n",
    "            emotions = emotions.to(device)\n",
    "            review_embeddings = review_embeddings.to(device)\n",
    "            user_indices = user_indices.to(device)\n",
    "\n",
    "            outputs, _ = model(noisy_user_vectors, user_indices, user_indices, emotions, review_embeddings)\n",
    "            loss = criterion(outputs, user_vectors)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    average_loss = running_loss / len(dataloader)\n",
    "    return average_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c220f5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-01T17:18:12.956733Z",
     "iopub.status.busy": "2024-08-01T17:18:12.956493Z",
     "iopub.status.idle": "2024-08-01T17:18:12.966788Z",
     "shell.execute_reply": "2024-08-01T17:18:12.966045Z"
    },
    "papermill": {
     "duration": 0.017705,
     "end_time": "2024-08-01T17:18:12.968603",
     "exception": false,
     "start_time": "2024-08-01T17:18:12.950898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False, delta=0, path='cdae_checkpoint.pth'):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        \"\"\"Saves model when validation loss decreases.\"\"\"\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving CDAE model...')\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "        }, self.path)\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "    def load_checkpoint(self, model):\n",
    "        \"\"\"Loads the best saved model.\"\"\"\n",
    "        checkpoint = torch.load(self.path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        return checkpoint['val_loss']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "121d6072",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-01T17:18:12.978893Z",
     "iopub.status.busy": "2024-08-01T17:18:12.978642Z",
     "iopub.status.idle": "2024-08-01T17:18:13.668675Z",
     "shell.execute_reply": "2024-08-01T17:18:13.667581Z"
    },
    "papermill": {
     "duration": 0.69814,
     "end_time": "2024-08-01T17:18:13.671243",
     "exception": false,
     "start_time": "2024-08-01T17:18:12.973103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Initialize model\n",
    "model = CDAE(num_users, num_items, num_emotions, review_embedding_dim, \n",
    "             embedding_dim=32, hidden_dims=[256, 128, 64], dropout=0.2).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1caab657",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-01T17:18:13.683597Z",
     "iopub.status.busy": "2024-08-01T17:18:13.683232Z",
     "iopub.status.idle": "2024-08-01T17:18:14.455297Z",
     "shell.execute_reply": "2024-08-01T17:18:14.453963Z"
    },
    "papermill": {
     "duration": 0.78045,
     "end_time": "2024-08-01T17:18:14.457222",
     "exception": true,
     "start_time": "2024-08-01T17:18:13.676772",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      8\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user, item, emotion, review_emb, rating \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     10\u001b[0m     user \u001b[38;5;241m=\u001b[39m user\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m     item \u001b[38;5;241m=\u001b[39m item\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m, in \u001b[0;36mcustom_collate_fn\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcustom_collate_fn\u001b[39m(batch):\n\u001b[0;32m----> 2\u001b[0m     user_vectors, user_indices, emotions, review_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch)\n\u001b[1;32m      4\u001b[0m     user_vectors \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(user_vectors)\n\u001b[1;32m      5\u001b[0m     user_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(user_indices, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Initialize EarlyStopping object\n",
    "early_stopping = EarlyStopping(patience=5, verbose=True, path='/kaggle/working/cdaemodel.pth')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for user, item, emotion, review_emb, rating in train_loader:\n",
    "        user = user.to(device)\n",
    "        item = item.to(device)\n",
    "        emotion = emotion.to(device)\n",
    "        review_emb = review_emb.to(device)\n",
    "        rating = rating.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        prediction, _ = model(user, item, emotion, review_emb)\n",
    "        loss = criterion(prediction, rating)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * user.size(0)\n",
    "\n",
    "    # Compute average training loss\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for user, item, emotion, review_emb, rating in test_loader:\n",
    "            user = user.to(device)\n",
    "            item = item.to(device)\n",
    "            emotion = emotion.to(device)\n",
    "            review_emb = review_emb.to(device)\n",
    "            rating = rating.to(device)\n",
    "\n",
    "            prediction, _ = model(user, item, emotion, review_emb)\n",
    "            loss = criterion(prediction, rating)\n",
    "            val_loss += loss.item() * user.size(0)\n",
    "\n",
    "        val_loss /= len(test_loader.dataset)\n",
    "\n",
    "    # Print training and validation loss\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "    # Update early stopping object\n",
    "    early_stopping(val_loss, model)\n",
    "\n",
    "    # Check if early stopping criterion is met\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "# Load the best model checkpoint\n",
    "model.load_state_dict(torch.load('/kaggle/working/cdaemodel.pth'))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5480558,
     "sourceId": 9083525,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5480872,
     "sourceId": 9083967,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 97902,
     "modelInstanceId": 73022,
     "sourceId": 86942,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 21.263231,
   "end_time": "2024-08-01T17:18:17.017630",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-01T17:17:55.754399",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
